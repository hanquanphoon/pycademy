{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter. Sometimes we are only interested in certain lines in the RDD of which the value of a certain column is a certain number or a certain range. For example, say in the previous fake friends problem, if we are only interested in 33 year olds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 385),\n",
       " (33, 74),\n",
       " (33, 471),\n",
       " (33, 275),\n",
       " (33, 245),\n",
       " (33, 356),\n",
       " (33, 460),\n",
       " (33, 294),\n",
       " (33, 243),\n",
       " (33, 463),\n",
       " (33, 228),\n",
       " (33, 410)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"FriendsByAge\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    age = int(fields[2])\n",
    "    numFriends = int(fields[3])\n",
    "    return (age, numFriends)\n",
    "\n",
    "lines = sc.textFile(\"fakefriends.csv\")\n",
    "rdd = lines.map(parseLine)\n",
    "thirtythreeyo = rdd.filter(lambda x: x[0]==33)\n",
    "thirtythreeyo.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a certain range, says between 40 and 49, inclusive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40, 465),\n",
       " (43, 49),\n",
       " (45, 455),\n",
       " (42, 363),\n",
       " (49, 476),\n",
       " (48, 364),\n",
       " (43, 249),\n",
       " (40, 254),\n",
       " (41, 278),\n",
       " (44, 194),\n",
       " (48, 135),\n",
       " (45, 184),\n",
       " (40, 459),\n",
       " (40, 407),\n",
       " (46, 88),\n",
       " (46, 63),\n",
       " (44, 178),\n",
       " (40, 18),\n",
       " (41, 244),\n",
       " (45, 400),\n",
       " (45, 439),\n",
       " (47, 429),\n",
       " (40, 284),\n",
       " (45, 252),\n",
       " (46, 462),\n",
       " (45, 340),\n",
       " (42, 427),\n",
       " (45, 470),\n",
       " (49, 340),\n",
       " (40, 389),\n",
       " (44, 360),\n",
       " (48, 57),\n",
       " (47, 87),\n",
       " (43, 404),\n",
       " (47, 488),\n",
       " (44, 84),\n",
       " (48, 287),\n",
       " (47, 225),\n",
       " (40, 349),\n",
       " (45, 497),\n",
       " (48, 381),\n",
       " (46, 125),\n",
       " (41, 206),\n",
       " (41, 394),\n",
       " (40, 406),\n",
       " (44, 277),\n",
       " (40, 198),\n",
       " (49, 22),\n",
       " (48, 345),\n",
       " (46, 154),\n",
       " (45, 332),\n",
       " (41, 260),\n",
       " (40, 172),\n",
       " (40, 33),\n",
       " (49, 106),\n",
       " (44, 353),\n",
       " (47, 13),\n",
       " (46, 300),\n",
       " (44, 499),\n",
       " (43, 101),\n",
       " (40, 56),\n",
       " (45, 395),\n",
       " (49, 147),\n",
       " (46, 319),\n",
       " (41, 340),\n",
       " (45, 59),\n",
       " (43, 48),\n",
       " (44, 61),\n",
       " (46, 407),\n",
       " (40, 7),\n",
       " (47, 4),\n",
       " (46, 151),\n",
       " (46, 352),\n",
       " (41, 397),\n",
       " (48, 266),\n",
       " (47, 97),\n",
       " (43, 335),\n",
       " (42, 467),\n",
       " (45, 147),\n",
       " (40, 261),\n",
       " (44, 388),\n",
       " (45, 54),\n",
       " (42, 275),\n",
       " (42, 95),\n",
       " (48, 394),\n",
       " (46, 105),\n",
       " (40, 286),\n",
       " (48, 439),\n",
       " (44, 337),\n",
       " (44, 335),\n",
       " (47, 400),\n",
       " (41, 236),\n",
       " (40, 220),\n",
       " (42, 194),\n",
       " (46, 227),\n",
       " (41, 62),\n",
       " (44, 320),\n",
       " (43, 428),\n",
       " (48, 146),\n",
       " (47, 356),\n",
       " (49, 17),\n",
       " (46, 155)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forties = rdd.filter(lambda x: 40 <= x[0] <= 49)\n",
    "forties.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find minimum. Say we only want to know the minimum number of friends each age has. The code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 74),\n",
       " (26, 2),\n",
       " (55, 57),\n",
       " (40, 7),\n",
       " (68, 21),\n",
       " (59, 14),\n",
       " (37, 46),\n",
       " (54, 7),\n",
       " (38, 2),\n",
       " (27, 53),\n",
       " (53, 86),\n",
       " (57, 8),\n",
       " (56, 15),\n",
       " (43, 48),\n",
       " (36, 49),\n",
       " (22, 6),\n",
       " (35, 13),\n",
       " (45, 54),\n",
       " (60, 2),\n",
       " (67, 35),\n",
       " (19, 5),\n",
       " (30, 17),\n",
       " (51, 81),\n",
       " (25, 1),\n",
       " (21, 89),\n",
       " (42, 95),\n",
       " (49, 17),\n",
       " (48, 57),\n",
       " (50, 119),\n",
       " (39, 68),\n",
       " (32, 24),\n",
       " (58, 6),\n",
       " (64, 65),\n",
       " (31, 15),\n",
       " (52, 77),\n",
       " (24, 49),\n",
       " (20, 1),\n",
       " (62, 12),\n",
       " (41, 62),\n",
       " (44, 61),\n",
       " (69, 9),\n",
       " (65, 101),\n",
       " (61, 2),\n",
       " (28, 32),\n",
       " (66, 41),\n",
       " (46, 63),\n",
       " (29, 11),\n",
       " (18, 24),\n",
       " (47, 4),\n",
       " (34, 48),\n",
       " (63, 342),\n",
       " (23, 65)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minim = rdd.reduceByKey(lambda x,y: min(x,y))\n",
    "minim.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That tells us, for example, of all friends who are 33 years old, the one with the fewest friends has 74 friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flat map. The <code>map</code> function transforms an RDD to another, but the number of lines in the new RDD is the same as the original RDD. To transform an RDD to another with a different number of lines, we need to use a different function called <code>flatMap</code>. For example, say we have a file of a book and we want to know how many words are in the book. We shall first load the book into an RDD in our program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-Employment: Building an Internet Business of One',\n",
       " 'Achieving Financial and Personal Freedom through a Lifestyle Technology Business',\n",
       " 'By Frank Kane',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Copyright � 2015 Frank Kane. ',\n",
       " 'All rights reserved worldwide.',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"Book\")\n",
    "lines.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here the book is separated into lines. So if we want to transform the RDD into another RDD but separated into words, we need the <code>flatMap</code> function. First of all, if we want to split the first line, which is a Python string, into a list of words, assuming words are separated by a space, the code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-Employment:', 'Building', 'an', 'Internet', 'Business', 'of', 'One']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.collect()[0].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore to write it into a lambda function and apply it to Pyspark, the code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-Employment:',\n",
       " 'Building',\n",
       " 'an',\n",
       " 'Internet',\n",
       " 'Business',\n",
       " 'of',\n",
       " 'One',\n",
       " 'Achieving',\n",
       " 'Financial',\n",
       " 'and',\n",
       " 'Personal',\n",
       " 'Freedom',\n",
       " 'through',\n",
       " 'a',\n",
       " 'Lifestyle',\n",
       " 'Technology',\n",
       " 'Business',\n",
       " 'By',\n",
       " 'Frank',\n",
       " 'Kane',\n",
       " 'Copyright',\n",
       " '�',\n",
       " '2015',\n",
       " 'Frank',\n",
       " 'Kane.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda x: x.split())\n",
    "words.collect()[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Pyspark has a simple function that counts the number of lines in an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46249"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to know the frequency of each different word that appears in the book. There is also another simple Pyspark function for that, countByValue. It returns a dictionary, of which the keys are unique words and the values are their respective frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the result, we can see that there are some potential improvements we can make. For example, a word followed by a punctuation appears to count as a separate word from the same word that does not, as does a word with letters in a different case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting. One way we might want to present our word count result is by the frequency, with the most common word first. But Pyspark only has a sortByKey function, which will sort the result in alphabetical order. One neat trick we can use is to simply flip the key and value in our key-value pair, then sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = words.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)\n",
    "wordCountSorted = wordCount.map(lambda x: (x[1],x[0])).sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1789, 'to'),\n",
       " (1339, 'your'),\n",
       " (1267, 'you'),\n",
       " (1176, 'the'),\n",
       " (1148, 'a'),\n",
       " (941, 'of'),\n",
       " (901, 'and'),\n",
       " (641, 'that'),\n",
       " (552, 'in'),\n",
       " (531, 'is'),\n",
       " (500, 'for'),\n",
       " (399, 'on'),\n",
       " (391, 'are'),\n",
       " (347, 'be'),\n",
       " (322, 'I'),\n",
       " (319, 'can'),\n",
       " (311, 'it'),\n",
       " (299, 'have'),\n",
       " (297, 'as'),\n",
       " (292, 'with'),\n",
       " (267, 'or'),\n",
       " (261, 'business'),\n",
       " (237, 'If'),\n",
       " (220, 'will'),\n",
       " (208, 'this'),\n",
       " (199, 'my'),\n",
       " (192, 'they'),\n",
       " (192, 'but'),\n",
       " (189, 'at'),\n",
       " (187, 'more'),\n",
       " (181, 'about'),\n",
       " (177, 'what'),\n",
       " (174, '�'),\n",
       " (174, 'if'),\n",
       " (172, 'an'),\n",
       " (169, 'not'),\n",
       " (166, 'need'),\n",
       " (165, 'time'),\n",
       " (161, 'from'),\n",
       " (159, \"you're\"),\n",
       " (156, 'do'),\n",
       " (155, 'up'),\n",
       " (144, 'You'),\n",
       " (143, 'new'),\n",
       " (138, 'out'),\n",
       " (131, 'just'),\n",
       " (127, 'how'),\n",
       " (125, 'product'),\n",
       " (122, 'people'),\n",
       " (117, 'their')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountSorted.collect()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: total spent by customers. The customer-orders.csv file contains data about orders some customers made in a store. The first column of the table is the customer ID, the second column the order ID, and the third column the cost of that order. Using Pyspark, compile a list of the highest spending customers in the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6375.449999999997, 68),\n",
       " (6206.199999999999, 73),\n",
       " (6193.109999999999, 39),\n",
       " (6065.389999999999, 54),\n",
       " (5995.660000000003, 71),\n",
       " (5994.59, 2),\n",
       " (5977.189999999995, 97),\n",
       " (5963.109999999999, 46),\n",
       " (5696.840000000003, 42),\n",
       " (5642.89, 59),\n",
       " (5637.62, 41),\n",
       " (5524.949999999998, 0),\n",
       " (5517.240000000001, 8),\n",
       " (5503.43, 85),\n",
       " (5497.479999999998, 61),\n",
       " (5496.050000000004, 32),\n",
       " (5437.7300000000005, 58),\n",
       " (5415.150000000001, 63),\n",
       " (5413.510000000001, 15),\n",
       " (5397.879999999998, 6),\n",
       " (5379.280000000002, 92),\n",
       " (5368.83, 43),\n",
       " (5368.249999999999, 70),\n",
       " (5337.44, 72),\n",
       " (5330.8, 34),\n",
       " (5322.649999999999, 9),\n",
       " (5298.090000000002, 55),\n",
       " (5290.409999999998, 90),\n",
       " (5288.689999999996, 64),\n",
       " (5265.750000000001, 93),\n",
       " (5259.920000000003, 24),\n",
       " (5254.659999999998, 33),\n",
       " (5253.3200000000015, 62),\n",
       " (5250.4, 26),\n",
       " (5245.059999999999, 52),\n",
       " (5206.4, 87),\n",
       " (5186.429999999999, 40),\n",
       " (5155.419999999999, 35),\n",
       " (5152.290000000002, 11),\n",
       " (5140.3499999999985, 65),\n",
       " (5123.010000000001, 69),\n",
       " (5112.709999999999, 81),\n",
       " (5059.4299999999985, 19),\n",
       " (5057.610000000001, 25),\n",
       " (5040.709999999999, 60),\n",
       " (5032.679999999999, 17),\n",
       " (5032.529999999999, 29),\n",
       " (5019.449999999999, 22),\n",
       " (5000.709999999998, 28),\n",
       " (4990.72, 30),\n",
       " (4979.06, 16),\n",
       " (4975.22, 51),\n",
       " (4958.600000000001, 1),\n",
       " (4945.299999999999, 53),\n",
       " (4921.27, 18),\n",
       " (4915.889999999999, 27),\n",
       " (4908.81, 86),\n",
       " (4904.209999999999, 76),\n",
       " (4898.460000000002, 38),\n",
       " (4876.840000000002, 95),\n",
       " (4851.479999999999, 89),\n",
       " (4836.859999999999, 20),\n",
       " (4830.549999999999, 88),\n",
       " (4819.700000000001, 10),\n",
       " (4815.050000000002, 4),\n",
       " (4812.489999999998, 82),\n",
       " (4765.05, 31),\n",
       " (4756.8899999999985, 44),\n",
       " (4755.070000000001, 7),\n",
       " (4735.200000000002, 37),\n",
       " (4735.030000000001, 14),\n",
       " (4727.860000000001, 80),\n",
       " (4707.41, 21),\n",
       " (4701.019999999999, 56),\n",
       " (4681.919999999999, 66),\n",
       " (4664.589999999998, 12),\n",
       " (4659.63, 3),\n",
       " (4652.939999999999, 84),\n",
       " (4647.129999999999, 74),\n",
       " (4642.259999999999, 91),\n",
       " (4635.799999999997, 83),\n",
       " (4628.4, 57),\n",
       " (4561.069999999999, 5),\n",
       " (4524.509999999999, 78),\n",
       " (4517.27, 50),\n",
       " (4505.79, 67),\n",
       " (4475.569999999999, 94),\n",
       " (4394.599999999999, 49),\n",
       " (4384.33, 48),\n",
       " (4367.62, 13),\n",
       " (4327.729999999999, 77),\n",
       " (4316.299999999999, 47),\n",
       " (4297.260000000001, 98),\n",
       " (4278.049999999997, 36),\n",
       " (4178.500000000001, 75),\n",
       " (4172.289999999998, 99),\n",
       " (4042.6499999999987, 23),\n",
       " (3924.230000000001, 96),\n",
       " (3790.570000000001, 79),\n",
       " (3309.38, 45)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"customer-orders.csv\")\n",
    "def parseLine(line):\n",
    "    fields = line.split(\",\")\n",
    "    cust = int(fields[0])\n",
    "    amount = float(fields[2])\n",
    "    return (cust,amount)\n",
    "rdd = lines.map(parseLine)\n",
    "totalByCustomer = rdd.reduceByKey(lambda x,y: x+y)\n",
    "totalByCustomer.map(lambda x: (x[1],x[0])).sortByKey(ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
